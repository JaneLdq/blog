<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/blog/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/blog/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/blog/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/blog/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/blog/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/blog/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/blog/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="爬虫," />










<meta name="description" content="在这个阳光明媚的周末下午，我决定写一篇笔记纪念一下我写第二只爬虫的心路历程，毕竟苦苦挣扎了将近一个月呢。 以下为本人的碎碎念，看正文可直接跳过去下一小节了~ 为什么是第二只呢，因为第一只虫子头脑简单四肢发达，顺利出生在狗年春节之前。那是在我还是一个彻头彻尾的爬虫小白的时候，在老司机们的推荐下用框架Scrapy以汽车之家-搜索文章页面为入口写了一个简单的以关键词为输入爬取搜索结果页面的爬虫，这个过程">
<meta property="og:type" content="article">
<meta property="og:title" content="一只爬虫的难产之旅（一）">
<meta property="og:url" content="http://liaodanqi.xyz/blog/2018/04/08/autohome-spider-1/index.html">
<meta property="og:site_name" content="Jane">
<meta property="og:description" content="在这个阳光明媚的周末下午，我决定写一篇笔记纪念一下我写第二只爬虫的心路历程，毕竟苦苦挣扎了将近一个月呢。 以下为本人的碎碎念，看正文可直接跳过去下一小节了~ 为什么是第二只呢，因为第一只虫子头脑简单四肢发达，顺利出生在狗年春节之前。那是在我还是一个彻头彻尾的爬虫小白的时候，在老司机们的推荐下用框架Scrapy以汽车之家-搜索文章页面为入口写了一个简单的以关键词为输入爬取搜索结果页面的爬虫，这个过程">
<meta property="og:locale">
<meta property="og:image" content="http://static.zybuluo.com/JaneL/qcslb6i8nj91kikp66g0joup/spider-structure.PNG">
<meta property="og:image" content="http://static.zybuluo.com/JaneL/4un9ajhraio6l92ckqu9wdp4/get_car_list_api.PNG">
<meta property="og:image" content="http://static.zybuluo.com/JaneL/7ehin4n9z6jelk6is6oc75mm/get_car_list_api_result.PNG">
<meta property="article:published_time" content="2018-04-08T07:56:39.000Z">
<meta property="article:modified_time" content="2021-08-04T10:07:48.609Z">
<meta property="article:author" content="Jane Liao">
<meta property="article:tag" content="爬虫">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://static.zybuluo.com/JaneL/qcslb6i8nj91kikp66g0joup/spider-structure.PNG">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '',
    scheme: 'Mist',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://liaodanqi.xyz/blog/2018/04/08/autohome-spider-1/"/>





  <title>一只爬虫的难产之旅（一） | Jane</title>
  








<meta name="generator" content="Hexo 5.4.0"></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/blog/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Jane</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">Learn & Live</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/blog/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/blog/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/blog/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/blog/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://liaodanqi.xyz/blog/blog/2018/04/08/autohome-spider-1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/blog/uploads/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jane">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">一只爬虫的难产之旅（一）</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-04-08T07:56:39+00:00">
                2018-04-08
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/blog/categories/%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index">
                    <span itemprop="name">技术笔记</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>在这个阳光明媚的周末下午，我决定写一篇笔记纪念一下我写第二只爬虫的心路历程，毕竟苦苦挣扎了将近一个月呢。</p>
<p><em>以下为本人的碎碎念，看正文可直接跳过去下一小节了~</em></p>
<p>为什么是第二只呢，因为第一只虫子头脑简单四肢发达，顺利出生在狗年春节之前。那是在我还是一个彻头彻尾的爬虫小白的时候，在老司机们的推荐下用框架<a target="_blank" rel="noopener" href="https://scrapy.org/">Scrapy</a>以<a target="_blank" rel="noopener" href="https://sou.autohome.com.cn/wenzhang?prevType=0">汽车之家-搜索文章</a>页面为入口写了一个简单的以关键词为输入爬取搜索结果页面的爬虫，这个过程出人意料的顺利。</p>
<span id="more"></span>
<p>于是乎，一个愉快而美味的春节就这么过去了。</p>
<p>节后回来，得知根据需求还需要爬取更多的数据，日常挖坑坑自己的我挑中了<a target="_blank" rel="noopener" href="https://k.autohome.com.cn/">汽车之家-口碑</a>的数据。任务目标很简单，就是把口碑页面所有车系的所有口碑详细页面的内容爬取下来。</p>
<p>有了第一次的经验，这第二次还不是轻车熟路嘛。Scrapy这么好用，写个Item对应要存储的数据，写两个parse方法解析一下页面，保存一下，搞定！来，跑一下，欸欸欸欸？怎么翻车了？？？就这样，小狗仔爬虫的难产之旅就此开始。</p>
<p>就让我们从头回顾吧~</p>
<hr>
<p>爬虫需求：爬取<a target="_blank" rel="noopener" href="https://k.autohome.com.cn/">汽车之家口碑</a>数据<br>爬虫思路 - Verson 1：</p>
<ol>
<li>以<a target="_blank" rel="noopener" href="https://k.autohome.com.cn/">口碑车系列表页 - https://k.autohome.com.cn</a>为入口，获取所有<strong>车系列表页</strong>链接</li>
<li>爬取单个车系的<strong>口碑列表</strong>，获得口碑详情页链接（比如:<a target="_blank" rel="noopener" href="https://k.autohome.com.cn/146">奥迪A8怎么样 - https://k.autohome.com.cn/146</a>)</li>
<li>爬取每个<strong>口碑详情</strong>页（比如：<a target="_blank" rel="noopener" href="https://k.autohome.com.cn/detail/view_01c2dazamh64w3ae1n6wsg0000.html">A8使用感受，超级无敌详细 - https://k.autohome.com.cn/detail/view_01c2dazamh64w3ae1n6wsg0000.html</a> )</li>
</ol>
<hr>
<h2 id="搭架子-Scrapy是个好东西"><a href="#搭架子-Scrapy是个好东西" class="headerlink" title="搭架子 - Scrapy是个好东西"></a>搭架子 - Scrapy是个好东西</h2><p>由于时间比较赶，所以python爬虫的一些教程也都没有怎么仔细看过，就直接拿<a target="_blank" rel="noopener" href="https://scrapy.org/">Scrapy</a>上手了，真的很好用！<br>Scrapy是一个开源的python爬虫框架，不熟悉的朋友可以移步官方网站了解一下。<br>Scrapy项目建好后，项目目录如下所示：<br><img src="http://static.zybuluo.com/JaneL/qcslb6i8nj91kikp66g0joup/spider-structure.PNG" alt="spider-structure.PNG-32.9kB"></p>
<hr>
<h3 id="定义数据结构-创建Item"><a href="#定义数据结构-创建Item" class="headerlink" title="定义数据结构 - 创建Item"></a>定义数据结构 - 创建Item</h3><p>在<strong>items.py</strong>里新增<em>Feedback</em>类继承自<em>scrapy.Item</em>类，里面定义了想要爬取的内容字段，其中<em>items</em>字段存储每篇口碑的文字内容，这里用的复数表示这是一个列表，因为口碑作者在发表了一篇口碑之后，还可以再追加口碑，追加口碑的格式跟第一篇口碑的格式差不多，因此都存储在了<em>items</em>这个字段里，将来作为一个list存入数据库。</p>
<hr>
<h3 id="存储数据-创建Pipeline"><a href="#存储数据-创建Pipeline" class="headerlink" title="存储数据 - 创建Pipeline"></a>存储数据 - 创建Pipeline</h3><p>在这个爬虫项目中，我将爬取的数据存储在了MongoDB中，非关系型数据库用起来相当方便了~<br>要完成这一操作主要需要如下两步：</p>
<ol>
<li>在<strong>settings.py</strong>中添加MongoDB的配置信息（这一步不是必须哒，如果你不想配settings，也可以直接硬编码啦）</li>
<li>在<strong>pipelines.py</strong>中新增<em>FeedbackMongoPipeline</em>类，在<em>process_item</em>方法中将<em>item</em>存入数据库。</li>
</ol>
<hr>
<h3 id="创建spider"><a href="#创建spider" class="headerlink" title="创建spider"></a>创建spider</h3><p>数据结构定义好了，存储也搞定了，现在就剩下最关键的一步——<strong>数据爬取</strong>。不要方，有了Scrapy，数据爬取也变得超简单~<br>在<strong>spiders</strong>文件夹下创建<strong>feedbacks_spider.py</strong>，里面定义<em>FeedbacksSpider</em>类继承自<em>scrapy.Spider</em>类，实现具体的爬虫逻辑。按照上文提到的爬虫思路，这个类主要定义了三个方法：</p>
<h4 id="def-start-requests"><a href="#def-start-requests" class="headerlink" title="def start_requests"></a>def start_requests</h4><p>这是Spider类的入口方法，按照最初的思路，这个方法只需要返回一个<em>Request</em>，url=<a target="_blank" rel="noopener" href="https://k.autohome.com.cn">https://k.autohome.com.cn</a> ，然后交给一个callback解析获取跳转到所有车系的link，但是实际操作时，我并没有这样做。在访问这个url时，我发现戳不同的筛选条件，网站都会发送一个ajax请求调用一个API，如下图所示：<br><img src="http://static.zybuluo.com/JaneL/4un9ajhraio6l92ckqu9wdp4/get_car_list_api.PNG" alt="get_car_list_api.PNG-49.7kB"></p>
<p>使用postman访问这个API-<a target="_blank" rel="noopener" href="https://k.autohome.com.cn/ajax/getSceneSelectCar?minprice=2&amp;maxprice=110&amp;_appid=koubei&amp;level=3">https://k.autohome.com.cn/ajax/getSceneSelectCar?minprice=2&amp;maxprice=110&amp;_appid=koubei&amp;level=3</a> ，可以得到一个JSON对象，如下图所示：<br><img src="http://static.zybuluo.com/JaneL/7ehin4n9z6jelk6is6oc75mm/get_car_list_api_result.PNG" alt="get_car_list_api_result.PNG-21kB"></p>
<p>这是result是一个list，里面返回了全部符合筛选条件的车系的基本信息，你会发现，高亮部分的<strong>SeriesId</strong>对我们的爬虫非常有用，因为车系口碑列表页link长这样<code>https://k.autohome.com.cn/&#123;SeriesId&#125;</code>。</p>
<p>有了这个发现，我们就不需要先爬取口碑入口页，再解析这个页面获取车系列表页链接，更新后的<strong>爬虫思路-Version 2</strong>：</p>
<ol>
<li>调用API获取所有车系的SeriesId</li>
<li>使用SeriesId拼接车系口碑列表页的link，爬取单个车系的口碑列表，获得口碑详情页链接</li>
<li>爬取每个口碑详情页</li>
</ol>
<p>然而，这还不是最终版本的爬虫过程，因为V2版本是一个非常完美的过程，在爬取的每一步中我们都能顺利获取数据。而真正实现的时候，就无法忽视中途go die这种悲伤的事实了。比如每个车系的口碑列表页是分页的，有的车系有很多口碑，可能高达一两百页，如果爬到中间断掉了，照如上实现方式，只能从头来过。而还有，可能有的口碑详情页面访问失败了，数据没有爬取到，就丢失了。因此，为了解决上述两种失败情况，我在数据库中多定义了两个集合：</p>
<ul>
<li><p><strong>series_ids</strong>: 有两个字段，一个是id，一个是index。用途如下：</p>
<ol>
<li>在爬虫初次爬取之前，调用API获取所有SeriesId存入数据库。</li>
<li>爬虫开始之后，如果某个车系的口碑全部爬取完成，即在解析时没有<em>下一页</em>了，则将此SeriesId从数据库中删除。</li>
<li>若爬取到某个车系口碑列表的第n页时，失败了，则将n存入数据库，下次重启爬虫时，直接从第n页开始爬取。</li>
</ol>
</li>
<li><p><strong>failed_detail_pages</strong>: 当爬取口碑详情页失败时，就将该详情页的id存入数据库，下次重启爬虫时，除了爬取列表页，也会重新爬取之前访问失败的详情页。</p>
</li>
</ul>
<p>在不断改进之后，我们有了<strong>爬虫思路 - Version 3</strong>：</p>
<ol>
<li>调用API获取所有车系的SeriesId并存入数据库</li>
<li>从数据库中读取SeriesId，根据id和index访问对应车系口碑列表页<ol>
<li>若访问成功，获取口碑详情页链接，爬取口碑详情页数据，若访问失败，则将失败的详情页id存入数据库</li>
<li>若访问失败，将当前访问的列表页index更新至数据库</li>
</ol>
</li>
<li>从数据库读取之前访问失败的口碑详情页，若此次访问成功，则爬取数据之后将id从失败列表中删除</li>
</ol>
<p>综上，在start_requests中小蜘蛛们将会被分为两支队伍分别前进，一支爬取列表页，一支爬取之前失败的详情页，并分别交给以下两个不同的callback做解析。</p>
<hr>
<p>Scrapy提供了两种解析页面的选择器，一种是<a target="_blank" rel="noopener" href="https://www.w3.org/TR/selectors/">CSS</a>，一种是<a target="_blank" rel="noopener" href="https://www.w3.org/TR/xpath/">XPath</a>。听说XPath效率会高一点，所以在项目中我用的是Xpath选择器。不熟悉XPath的话，在解析页面时可以借助一些工具，比如Chrome的插件<a target="_blank" rel="noopener" href="https://chrome.google.com/webstore/detail/selectorgadget/mhjhnkcfbdhnjickkkdbjoemdmbfginb">SelectorGadget</a>等。</p>
<hr>
<h4 id="def-parse-feedback-list"><a href="#def-parse-feedback-list" class="headerlink" title="def parse_feedback_list"></a>def parse_feedback_list</h4><p>这个方法用于解析列表页，在实际跑爬虫的过程中我发现如果访问过于频繁，汽车之家会重定向请求到一个用户验证地址（要填很随机的验证码，有时是拖动拼图，有时是按指定顺序戳汉字，就很迷<em>(:з)∠)</em>，我还没有想出解决方案），这个列表页就算是访问失败了因此现在用的workaround就如前所述，将失败的index存储到数据库中，下次开启爬虫重新尝试访问。<br>这就要求用到SeriesId这个数据，Scrapy中在创建请求时提供了一个参数叫<code>meta</code>，用户可以自定义一些参数过来，这样获取到response对象后，可以从<code>response.meta</code>中读到之前传入的数据。</p>
<p>传入SeriesId示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">start_requests</span>(<span class="params">self, level=<span class="literal">None</span></span>):</span></span><br><span class="line">    <span class="comment"># ...</span></span><br><span class="line">    link = link = <span class="string">&#x27;https://k.autohome.com.cn/197&#x27;</span>)</span><br><span class="line">    <span class="comment"># 这里以series_id：197为例，将其通过meta参数传给了callback</span></span><br><span class="line">    <span class="keyword">yield</span> scrapy.Request(url=link, headers=self.headers, dont_filter=<span class="literal">True</span>, callback=self.parse_feedback_list, meta=&#123;<span class="string">&#x27;series_id&#x27;</span>: <span class="number">197</span>&#125;)</span><br></pre></td></tr></table></figure>
<p>parse_feedback_list代码如下，其中有读取<code>meta</code>中的SeriesId：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_feedback_list</span>(<span class="params">self, response</span>):</span></span><br><span class="line">    <span class="comment"># if this crawled page is redirected to user verify page and get response 200</span></span><br><span class="line">    <span class="keyword">if</span> re.search(verify_page_regex, response.url):</span><br><span class="line">        index = re.search(index_regex, response.url).group(<span class="number">1</span>)</span><br><span class="line">        db.series_id.find_one_and_update(&#123;<span class="string">&#x27;id&#x27;</span>: response.meta[<span class="string">&#x27;series_id&#x27;</span>]&#125;, &#123;<span class="string">&#x27;$set&#x27;</span>: &#123;<span class="string">&#x27;index&#x27;</span>: index&#125;&#125;)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># 在response对象的meta字段中就包含了request创建时传入的自定义参数</span></span><br><span class="line">        self.logger.info(<span class="string">&quot;Crawling feedback of car series: %s&quot;</span> % response.meta[<span class="string">&#x27;series_id&#x27;</span>])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># get the feedback list for the specific car series</span></span><br><span class="line">        links = response.xpath(<span class="string">&quot;//div[@class=&#x27;mouthcon&#x27;]//div[contains(@class, &#x27;title-name&#x27;)]/a/@href&quot;</span>).extract()</span><br><span class="line">        <span class="keyword">for</span> link <span class="keyword">in</span> links:</span><br><span class="line">            <span class="keyword">yield</span> response.follow(url=link, headers=self.headers, dont_filter=<span class="literal">True</span>, callback=self.parse_feedback_page, errback=self.errback_httpbin, meta=response.meta)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># go to next page</span></span><br><span class="line">        next_page = response.xpath(<span class="string">&quot;//a[@class=&#x27;page-item-next&#x27;]/@href&quot;</span>).extract_first()</span><br><span class="line">        <span class="keyword">if</span> next_page <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">yield</span> response.follow(url=next_page, callback=self.parse_feedback_list, dont_filter=<span class="literal">True</span>, meta=response.meta)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># if successfully crawled the whole list page of one series, then delete the series id from db</span></span><br><span class="line">            db.series_id.find_one_and_delete(&#123;<span class="string">&#x27;id&#x27;</span>: response.meta[<span class="string">&#x27;series_id&#x27;</span>]&#125;)</span><br></pre></td></tr></table></figure><br>简单介绍一下上面这段代码的逻辑吧（我觉得注释写得还算清楚哒：</p>
<ol>
<li>首先对拿到的response.url进行判断，如果它已经重定向到了用户验证地址则更新数据库，放弃解析；否则，解析页面：<ol>
<li>获取该页所有的详情页地址，创建请求，交给回调函数parse_feedback_page处理</li>
<li>检查是否有下一页，如果有，获取下一页列表地址，创建请求，回调函数仍然是parse_feedback_list；如果没有，则该车系口碑列表页爬取结束，从数据库series_ids里删除该车系id</li>
</ol>
</li>
</ol>
<hr>
<h4 id="def-parse-feedback-page"><a href="#def-parse-feedback-page" class="headerlink" title="def parse_feedback_page"></a>def parse_feedback_page</h4><p>这个方法就是用来解析口碑详情页的了，在这里会创建一个先前在items.py里定义好的Feedback对象，然后使用XPath解析页面，给对应的字段塞数据，全部塞好之后，返回这个对象。</p>
<p>然后Scrapy就会调用配好的Pipeline，流水走起来~<br>在本项目中只有一个Pipeline要走，就是将Item保存到数据库中~</p>
<p>这里多说一句，Scrapy的Pipeline配置可以配置在全局settings.py文件中，也可以给每个spider单独配Pipeline，这里我采用的是单独配置的方式，因为项目中写了多个spider(第一只那个头脑简单的spider也放在这同一个项目里了~），单独配置可以让每个spider走不同的流水线，彼此不影响。</p>
<p>单独配置Pipeline也很简单啦，给FeedbacksSpider类中加入如下字段：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FeedbacksSpider</span>(<span class="params">scrapy.Spider</span>):</span></span><br><span class="line">    <span class="comment"># ...</span></span><br><span class="line">    custom_settings = &#123;</span><br><span class="line">        <span class="string">&#x27;ITEM_PIPELINES&#x27;</span>: &#123;</span><br><span class="line">            <span class="string">&#x27;autohomeSpider.pipelines.FeedbackMongoPipeline&#x27;</span>: <span class="number">300</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment"># ...</span></span><br></pre></td></tr></table></figure>
<hr>
<p>整个搭架子的过程看起来比较简单，作为小白还是get了一些经验滴。</p>
<ul>
<li>着手解析页面之前，除了审查元素看页面结构之外，看看页面的加载过程很有用，一方面说不定能发现可以直接调用的API，能拿到现成的结构化数据就再好不过了；另一方面，也能了解页面是否有用到ajax等异步加载方式，对后续页面的解析也会有影响的。</li>
<li>不要只想着直接拿现成的URL，用参数拼接URL也是很可取的方式。</li>
<li>用户验证真的是一个很让人头大的问题啊（爬虫与反爬真的是相爱相杀=。=</li>
</ul>
<p>到此为止，如果不出意外的话，应该爬虫就可以工作起来了，然鹅，事情远没有那么简单（此处应有表情包)，坑，这才算是刚刚准备好了。</p>
<p>欲知坑在何处，能否顺利填坑，请移步：</p>
<ul>
<li><a href="/blog/2018/04/11/autohome-spider-2/" title="[一只爬虫的难产之旅（二）]">[一只爬虫的难产之旅（二）]</a>。</li>
<li><a href="/blog/2018/04/23/autohome-spider-3/" title="[一只爬虫的难产之旅（三）]">[一只爬虫的难产之旅（三）]</a>
</li>
</ul>
<hr>
<p>代码都放在<a target="_blank" rel="noopener" href="https://github.com/JaneLdq/autohome-spider.git">Github</a>上了，两只爬虫因为都是爬的汽车之家，所以放在同一个Scrapy项目里了。老二其实到现在也没有能完全自由行动，还是时刻需要人盯着。</p>
<p>难过。</p>
<hr>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul>
<li><a target="_blank" rel="noopener" href="https://docs.scrapy.org/en/latest/">Scrapy文档</a></li>
</ul>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/blog/tags/%E7%88%AC%E8%99%AB/" rel="tag"># 爬虫</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/blog/2018/03/30/back-in-the-saddle/" rel="next" title="Back in the Saddle">
                <i class="fa fa-chevron-left"></i> Back in the Saddle
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/blog/2018/04/11/autohome-spider-2/" rel="prev" title="一只爬虫的难产之旅（二）">
                一只爬虫的难产之旅（二） <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/blog/uploads/avatar.jpg"
                alt="" />
            
              <p class="site-author-name" itemprop="name"></p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/blog/archives/%7C%7C%20archive">
              
                  <span class="site-state-item-count">75</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/blog/categories/index.html">
                  <span class="site-state-item-count">6</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/blog/tags/index.html">
                  <span class="site-state-item-count">39</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/JaneLdq" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:janeldq@163.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%90%AD%E6%9E%B6%E5%AD%90-Scrapy%E6%98%AF%E4%B8%AA%E5%A5%BD%E4%B8%9C%E8%A5%BF"><span class="nav-number">1.</span> <span class="nav-text">搭架子 - Scrapy是个好东西</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%9A%E4%B9%89%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E5%88%9B%E5%BB%BAItem"><span class="nav-number">1.1.</span> <span class="nav-text">定义数据结构 - 创建Item</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AD%98%E5%82%A8%E6%95%B0%E6%8D%AE-%E5%88%9B%E5%BB%BAPipeline"><span class="nav-number">1.2.</span> <span class="nav-text">存储数据 - 创建Pipeline</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%9B%E5%BB%BAspider"><span class="nav-number">1.3.</span> <span class="nav-text">创建spider</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#def-start-requests"><span class="nav-number">1.3.1.</span> <span class="nav-text">def start_requests</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#def-parse-feedback-list"><span class="nav-number">1.3.2.</span> <span class="nav-text">def parse_feedback_list</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#def-parse-feedback-page"><span class="nav-number">1.3.3.</span> <span class="nav-text">def parse_feedback_page</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99"><span class="nav-number">2.</span> <span class="nav-text">参考资料</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2015 &mdash; <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Jane Liao</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/blog/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/blog/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/blog/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/blog/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/blog/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/blog/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/blog/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/blog/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/blog/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/blog/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/blog/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
